{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sasha_portrait_2.jpeg\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "input_dir = '/data/users/sash/stylegan/style-based-gan-pytorch/encoder/raw_images'\n",
    "input_image = random.choice(os.listdir(input_dir))\n",
    "input_image_path = input_dir + \"/\" + input_image\n",
    "print(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/data/users/sash/stylegan/style-based-gan-pytorch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_image_folder = \"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/aligned_images_run\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from encoder.ffhq_dataset.face_alignment import image_align\n",
    "from encoder.ffhq_dataset.landmarks_detector import LandmarksDetector\n",
    "\n",
    "def unpack_bz2(src_path):\n",
    "    data = bz2.BZ2File(src_path).read()\n",
    "    dst_path = src_path[:-4]\n",
    "    with open(dst_path, 'wb') as fp:\n",
    "        fp.write(data)\n",
    "    return dst_path\n",
    "\n",
    "\n",
    "def align_image(input_image_path, aligned_dir):\n",
    "    \"\"\"\n",
    "    Extracts and aligns all faces from images using DLib and a function from original FFHQ dataset preparation step\n",
    "    python align_images.py /raw_images /aligned_images\n",
    "    \"\"\"\n",
    "\n",
    "    landmarks_model_path = unpack_bz2(\"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/models/shape_predictor_68_face_landmarks.dat.bz2\")\n",
    "    ALIGNED_IMAGES_DIR = aligned_dir\n",
    "    img_name = input_image\n",
    "    landmarks_detector = LandmarksDetector(landmarks_model_path)\n",
    "    \n",
    "    for i, face_landmarks in enumerate(landmarks_detector.get_landmarks(input_image_path), start=1):\n",
    "        face_img_name = '%s_%02d.png' % (os.path.splitext(img_name)[0], i)\n",
    "        aligned_face_path = os.path.join(ALIGNED_IMAGES_DIR, face_img_name)\n",
    "\n",
    "        image_align(input_image_path, aligned_face_path, face_landmarks)\n",
    "\n",
    "align_image(input_image_path, aligned_image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sasha_portrait_2_01.png',\n",
       " 'sasha_portrait_2_02.png',\n",
       " 'roman_01.png',\n",
       " 'zuck_01.png',\n",
       " 'charles_01.png',\n",
       " 'sasha_portrait_01.png',\n",
       " 'pranav_01.png']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(aligned_image_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, \"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sasha_portrait_2_01.png\n"
     ]
    }
   ],
   "source": [
    "aligned_image_name = [x for x in os.listdir(aligned_image_folder) if os.path.splitext(input_image)[0] in x][0]\n",
    "aligned_image_name_wo_extention = os.path.splitext(aligned_image_name)[0]\n",
    "aligned_image_path = aligned_image_folder + \"/\" + aligned_image_name\n",
    "print(aligned_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_path = \"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/latents/\"\n",
    "latent_file_path = latents_path + aligned_image_name_wo_extention +\".npy\"\n",
    "optimized_folder_path = \"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/optimized/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sasha_portrait_2_01'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.splitext(os.path.basename(latent_file_path))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing Latents.\n",
      "[2020-03-30 22:20:04,863][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-30 22:20:04,978][INFO] Successfully loaded!\n",
      "[2020-03-30 22:20:04,979][INFO]   `lod` of the loaded model is 0.0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Step: 999, Loss: 1.8740954399108887: 100%|██████████| 1000/1000 [03:34<00:00,  4.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from encoder.pytorch_stylegan_encoder.encode_image import main as encode_image\n",
    "\n",
    "args = [\n",
    "    \"--save_optimized_image\",\n",
    "    \"True\",\n",
    "    \"--image_path\",\n",
    "    aligned_image_path,\n",
    "    \"--dlatent_path\",\n",
    "    latent_file_path,\n",
    "]\n",
    "\n",
    "encode_image(args)\n",
    "optimized_img_path = \"/data/users/sash/stylegan/style-based-gan-pytorch/optimized.png\"\n",
    "os.rename(optimized_img_path, optimized_folder_path + \"optimized_\" + aligned_image_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sasha_portrait_2_01.npy', 'roman_01.npy', 'pranav_01.npy']\n",
      "['optimized_sasha_portrait_2_01.png', 'optimized_roman_01.png', 'optimized_pranav_01.png']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(latents_path))\n",
    "print(os.listdir(optimized_folder_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleMixing with WP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/latents/pranav_01.npy\n",
      "/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/latents/sasha_portrait_2_01.npy\n",
      "/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/morphed_intepolation/pranav_01_sasha_portrait_2_01\n"
     ]
    }
   ],
   "source": [
    "wp_path = latents_path + aligned_image_name_wo_extention + \".npy\"\n",
    "other_name = [f for f in os.listdir(latents_path) if aligned_image_name_wo_extention not in f][0]\n",
    "wp_other_path = latents_path + other_name\n",
    "morph_interpolation_result_folder = \"/data/users/sash/stylegan/style-based-gan-pytorch/encoder/pytorch_stylegan_encoder/morphed_intepolation/\"\n",
    "morphed_img_name = aligned_image_name_wo_extention + \"_\" + other_name[:-4]\n",
    "print(wp_path)\n",
    "print(wp_other_path)\n",
    "print(morph_interpolation_result_folder + morphed_img_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing Morphing Images\n",
      "Interpolated wps: torch.Size([6, 1, 18, 512])\n",
      "[2020-03-28 15:58:24,664][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:24,772][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:24,772][INFO]   `lod` of the loaded model is 0.0.\n",
      "[2020-03-28 15:58:25,187][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:25,306][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:25,306][INFO]   `lod` of the loaded model is 0.0.\n",
      "[2020-03-28 15:58:25,709][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:25,825][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:25,826][INFO]   `lod` of the loaded model is 0.0.\n",
      "[2020-03-28 15:58:26,224][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:26,340][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:26,340][INFO]   `lod` of the loaded model is 0.0.\n",
      "[2020-03-28 15:58:26,744][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:26,861][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:26,862][INFO]   `lod` of the loaded model is 0.0.\n",
      "[2020-03-28 15:58:27,260][INFO] Loading pytorch model from `encoder/pytorch_stylegan_encoder/InterFaceGAN/models/pretrain/stylegan_ffhq.pth`.\n",
      "[2020-03-28 15:58:27,374][INFO] Successfully loaded!\n",
      "[2020-03-28 15:58:27,375][INFO]   `lod` of the loaded model is 0.0.\n",
      "Interpolated images shape: torch.Size([3, 1024, 6144])\n"
     ]
    }
   ],
   "source": [
    "args = [\n",
    "    \"--morph_interpolation\",\n",
    "    \"True\",\n",
    "    \"--latent_path\",\n",
    "    wp_path,\n",
    "    \"--other_latent_path\",\n",
    "    wp_other_path,\n",
    "    \"--num_images\",\n",
    "    \"4\",\n",
    "    \"--morph_interpolation_image_path\",\n",
    "    morph_interpolation_result_folder + morphed_img_name + \".png\"\n",
    "]\n",
    "\n",
    "encode_image(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "bento_stylesheets": {
   "bento/extensions/flow/main.css": true,
   "bento/extensions/kernel_selector/main.css": true,
   "bento/extensions/kernel_ui/main.css": true,
   "bento/extensions/new_kernel/main.css": true,
   "bento/extensions/system_usage/main.css": true,
   "bento/extensions/theme/main.css": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
